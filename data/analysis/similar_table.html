<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style>
.r1 {font-style: italic}
.r2 {font-weight: bold}
.r3 {color: #c0c0c0; text-decoration-color: #c0c0c0}
.r4 {color: #008080; text-decoration-color: #008080}
.r5 {color: #800080; text-decoration-color: #800080}
.r6 {color: #008000; text-decoration-color: #008000}
body {
    color: #000000;
    background-color: #ffffff;
}
</style>
</head>
<body>
    <pre style="font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><code style="font-family:inherit"><span class="r1">                                                                                         Most similar documents                                                                                         </span>
┏━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓
┃<span class="r2">   ID </span>┃<span class="r2">                                                         Safety </span>┃<span class="r2">                Topic </span>┃<span class="r2">   ID </span>┃<span class="r2"> Ethics                                                         </span>┃<span class="r2"> Topic                </span>┃<span class="r2"> Sim.   </span>┃
┡━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩
│<span class="r3"> 1222 </span>│<span class="r4">  Fragmentation and the Future: Investigating Architectures for </span>│<span class="r4">   governance compute </span>│<span class="r5"> 1655 </span>│<span class="r5"> Should artificial intelligence governance be centralised?      </span>│<span class="r5"> governance compute   </span>│<span class="r6"> 0.9322 </span>│
│<span class="r3">      </span>│<span class="r4">                                    International AI Governance </span>│<span class="r4">        international </span>│<span class="r5">      </span>│<span class="r5"> Design lessons from history                                    </span>│<span class="r5"> international        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">           regulatory </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> regulatory           </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  544 </span>│<span class="r4">          Ethical and social risks of harm from Language Models </span>│<span class="r4">     gender bias word </span>│<span class="r5"> 2260 </span>│<span class="r5"> Taxonomy of risks posed by language models                     </span>│<span class="r5"> gender bias word     </span>│<span class="r6"> 0.9067 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">               facial </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> facial               </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  552 </span>│<span class="r4">      Sociotechnical Safety Evaluation of Generative AI Systems </span>│<span class="r4">     safety assurance </span>│<span class="r5"> 1868 </span>│<span class="r5"> Gaps in the Safety Evaluation of Generative AI                 </span>│<span class="r5"> safety assurance     </span>│<span class="r6"> 0.8965 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">              risk ml </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> risk ml              </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  525 </span>│<span class="r4">       From Plane Crashes to Algorithmic Harm: Applicability of </span>│<span class="r4">     safety assurance </span>│<span class="r5"> 1376 </span>│<span class="r5"> Beyond the ML model: Applying safety engineering frameworks to </span>│<span class="r5"> domain agent         </span>│<span class="r6"> 0.8829 </span>│
│<span class="r3">      </span>│<span class="r4">               Safety Engineering Frameworks for Responsible ML </span>│<span class="r4">              risk ml </span>│<span class="r5">      </span>│<span class="r5"> text-to-image development                                      </span>│<span class="r5"> reinforcement        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> training             </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  213 </span>│<span class="r4">      Improving fairness generalization through a sample-robust </span>│<span class="r4">  fairness fair group </span>│<span class="r5"> 1702 </span>│<span class="r5"> Putting fairness principles into practice: Challenges,         </span>│<span class="r5"> fairness fair group  </span>│<span class="r6"> 0.8811 </span>│
│<span class="r3">      </span>│<span class="r4">                                            optimization method </span>│<span class="r4">       discrimination </span>│<span class="r5">      </span>│<span class="r5"> metrics, and improvements                                      </span>│<span class="r5"> discrimination       </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   75 </span>│<span class="r4">      Developing safer AI-concepts from economics to the rescue </span>│<span class="r4">         domain agent </span>│<span class="r5"> 1436 </span>│<span class="r5"> Regulating artificial intelligence: Proposal for a global      </span>│<span class="r5"> intelligence wicked  </span>│<span class="r6"> 0.8705 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">        reinforcement </span>│<span class="r5">      </span>│<span class="r5"> solution                                                       </span>│<span class="r5"> humanity rbi         </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">             training </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   71 </span>│<span class="r4">         On conflicts between ethical and logical principles in </span>│<span class="r4">         domain agent </span>│<span class="r5"> 1614 </span>│<span class="r5"> Artificial intelligence and the purpose of social systems      </span>│<span class="r5"> domain agent         </span>│<span class="r6"> 0.8677 </span>│
│<span class="r3">      </span>│<span class="r4">                                        artificial intelligence </span>│<span class="r4">        reinforcement </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> reinforcement        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">             training </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> training             </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  995 </span>│<span class="r4">            Responsible AI Research Needs Impact Statements Too </span>│<span class="r4"> ethic course ethical </span>│<span class="r5"> 1425 </span>│<span class="r5"> Examining responsibility and deliberation in AI impact         </span>│<span class="r5"> ethic course ethical </span>│<span class="r6"> 0.8656 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">         introductory </span>│<span class="r5">      </span>│<span class="r5"> statements and ethics reviews                                  </span>│<span class="r5"> introductory         </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1223 </span>│<span class="r4">      Bridging the gap: the case for an ‘Incompletely Theorized </span>│<span class="r4">  intelligence wicked </span>│<span class="r5"> 1492 </span>│<span class="r5"> A survey of the potential long-term impacts of AI: How AI      </span>│<span class="r5"> intelligence wicked  </span>│<span class="r6"> 0.8563 </span>│
│<span class="r3">      </span>│<span class="r4">                                        Agreement’ on AI policy </span>│<span class="r4">         humanity rbi </span>│<span class="r5">      </span>│<span class="r5"> could lead to long-term changes in science, cooperation,       </span>│<span class="r5"> humanity rbi         </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5"> power, epistemics and values                                   </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1016 </span>│<span class="r4">                            AITA: AI trustworthiness assessment </span>│<span class="r4">                trust </span>│<span class="r5"> 2223 </span>│<span class="r5"> The relationship between trust in AI and trustworthy machine   </span>│<span class="r5"> domain agent         </span>│<span class="r6"> 0.8548 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">      trustworthiness </span>│<span class="r5">      </span>│<span class="r5"> learning technologies                                          </span>│<span class="r5"> reinforcement        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">  trustworthy account </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> training             </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   34 </span>│<span class="r4">      Mechanisms and Constraints Underpinning Ethically Aligned </span>│<span class="r4">         domain agent </span>│<span class="r5"> 2497 </span>│<span class="r5"> Mapping AI ethics: a meso-scale analysis of its charters and   </span>│<span class="r5"> ethic course ethical </span>│<span class="r6"> 0.8529 </span>│
│<span class="r3">      </span>│<span class="r4">         Artificial Intelligence Systems: An Exploration of key </span>│<span class="r4">        reinforcement </span>│<span class="r5">      </span>│<span class="r5"> manifestos                                                     </span>│<span class="r5"> introductory         </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                              Performance Areas </span>│<span class="r4">             training </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  871 </span>│<span class="r4">           A Multi-Level Framework for the AI Alignment Problem </span>│<span class="r4">      alignment value </span>│<span class="r5"> 1879 </span>│<span class="r5"> Measuring Human-AI Value Alignment in Large Language Models    </span>│<span class="r5"> alignment value      </span>│<span class="r6"> 0.8496 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">         align mathbf </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> align mathbf         </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1223 </span>│<span class="r4">      Bridging the gap: the case for an ‘Incompletely Theorized </span>│<span class="r4">  intelligence wicked </span>│<span class="r5"> 2497 </span>│<span class="r5"> Mapping AI ethics: a meso-scale analysis of its charters and   </span>│<span class="r5"> ethic course ethical </span>│<span class="r6"> 0.8466 </span>│
│<span class="r3">      </span>│<span class="r4">                                        Agreement’ on AI policy </span>│<span class="r4">         humanity rbi </span>│<span class="r5">      </span>│<span class="r5"> manifestos                                                     </span>│<span class="r5"> introductory         </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1016 </span>│<span class="r4">                            AITA: AI trustworthiness assessment </span>│<span class="r4">                trust </span>│<span class="r5"> 1810 </span>│<span class="r5"> A Formal Account of Trustworthiness: Connecting Intrinsic and  </span>│<span class="r5"> trust                </span>│<span class="r6"> 0.846  </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">      trustworthiness </span>│<span class="r5">      </span>│<span class="r5"> Perceived Trustworthiness                                      </span>│<span class="r5"> trustworthiness      </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">  trustworthy account </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> trustworthy account  </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  531 </span>│<span class="r4">    Natural language understanding with privacy-preserving bert </span>│<span class="r4">           privacy dp </span>│<span class="r5"> 2003 </span>│<span class="r5"> What does it mean for a language model to preserve privacy?    </span>│<span class="r5"> privacy dp           </span>│<span class="r6"> 0.8407 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">       differentially </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> differentially       </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">              private </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> private              </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  204 </span>│<span class="r4">                                  Gray-box adversarial training </span>│<span class="r4">   adversarial attack </span>│<span class="r5"> 1355 </span>│<span class="r5"> Adaptive adversarial training does not increase recourse costs </span>│<span class="r5"> adversarial attack   </span>│<span class="r6"> 0.8263 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">   robustness defense </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> robustness defense   </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1111 </span>│<span class="r4">                                   Towards Robust Saliency Maps </span>│<span class="r4">     video scene shot </span>│<span class="r5"> 2489 </span>│<span class="r5"> Classification metrics for image explanations: Towards         </span>│<span class="r5"> video scene shot     </span>│<span class="r6"> 0.826  </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">               vision </span>│<span class="r5">      </span>│<span class="r5"> building reliable XAI-evaluations                              </span>│<span class="r5"> vision               </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  972 </span>│<span class="r4">           Using In-Context Learning to Improve Dialogue Safety </span>│<span class="r4">       dialogue audio </span>│<span class="r5"> 1459 </span>│<span class="r5"> Ethical challenges in data-driven dialogue systems             </span>│<span class="r5"> dialogue audio       </span>│<span class="r6"> 0.8258 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4"> contradiction dialog </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> contradiction dialog </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  131 </span>│<span class="r4">       Towards Deep Anomaly Detection with Structured Knowledge </span>│<span class="r4">    anomaly detection </span>│<span class="r5"> 2149 </span>│<span class="r5"> Towards fair deep anomaly detection                            </span>│<span class="r5"> anomaly detection    </span>│<span class="r6"> 0.8249 </span>│
│<span class="r3">      </span>│<span class="r4">                                                Representations </span>│<span class="r4">          ood density </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> ood density          </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  476 </span>│<span class="r4">                                X-Risk Analysis for AI Research </span>│<span class="r4">     safety assurance </span>│<span class="r5"> 1500 </span>│<span class="r5"> Current and near-term AI as a potential existential risk       </span>│<span class="r5"> intelligence wicked  </span>│<span class="r6"> 0.824  </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">              risk ml </span>│<span class="r5">      </span>│<span class="r5"> factor                                                         </span>│<span class="r5"> humanity rbi         </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1224 </span>│<span class="r4">          Why and How Governments Should Monitor AI Development </span>│<span class="r4">   governance compute </span>│<span class="r5"> 2446 </span>│<span class="r5"> AI regulation is (not) all you need                            </span>│<span class="r5"> domain agent         </span>│<span class="r6"> 0.8187 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">        international </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> reinforcement        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">           regulatory </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> training             </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  792 </span>│<span class="r4">         Safety Engineering for Artificial General Intelligence </span>│<span class="r4">        moral ethical </span>│<span class="r5"> 1771 </span>│<span class="r5"> The dark side of ethical robots                                </span>│<span class="r5"> moral ethical        </span>│<span class="r6"> 0.8183 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">  obligation morality </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> obligation morality  </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1223 </span>│<span class="r4">      Bridging the gap: the case for an ‘Incompletely Theorized </span>│<span class="r4">  intelligence wicked </span>│<span class="r5"> 1682 </span>│<span class="r5"> Defining AI in policy versus practice                          </span>│<span class="r5"> governance compute   </span>│<span class="r6"> 0.8151 </span>│
│<span class="r3">      </span>│<span class="r4">                                        Agreement’ on AI policy </span>│<span class="r4">         humanity rbi </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> international        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> regulatory           </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  922 </span>│<span class="r4">      Application of Artificial Intelligence in Shared Decision </span>│<span class="r4">    healthcare health </span>│<span class="r5"> 1607 </span>│<span class="r5"> Co-design and ethical artificial intelligence for health:      </span>│<span class="r5"> healthcare health    </span>│<span class="r6"> 0.8149 </span>│
│<span class="r3">      </span>│<span class="r4">                                         Making: Scoping Review </span>│<span class="r4">         patient care </span>│<span class="r5">      </span>│<span class="r5"> Myths and misconceptions                                       </span>│<span class="r5"> patient care         </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  995 </span>│<span class="r4">            Responsible AI Research Needs Impact Statements Too </span>│<span class="r4"> ethic course ethical </span>│<span class="r5"> 1682 </span>│<span class="r5"> Defining AI in policy versus practice                          </span>│<span class="r5"> governance compute   </span>│<span class="r6"> 0.814  </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">         introductory </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> international        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> regulatory           </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   34 </span>│<span class="r4">      Mechanisms and Constraints Underpinning Ethically Aligned </span>│<span class="r4">         domain agent </span>│<span class="r5"> 1781 </span>│<span class="r5"> A Conceptual Framework for Ethical Evaluation of Machine       </span>│<span class="r5"> ml machine cleaning  </span>│<span class="r6"> 0.8126 </span>│
│<span class="r3">      </span>│<span class="r4">         Artificial Intelligence Systems: An Exploration of key </span>│<span class="r4">        reinforcement </span>│<span class="r5">      </span>│<span class="r5"> Learning Systems                                               </span>│<span class="r5"> replicability        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                              Performance Areas </span>│<span class="r4">             training </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   34 </span>│<span class="r4">      Mechanisms and Constraints Underpinning Ethically Aligned </span>│<span class="r4">         domain agent </span>│<span class="r5"> 1514 </span>│<span class="r5"> How does predictive information affect human ethical           </span>│<span class="r5"> healthcare health    </span>│<span class="r6"> 0.806  </span>│
│<span class="r3">      </span>│<span class="r4">         Artificial Intelligence Systems: An Exploration of key </span>│<span class="r4">        reinforcement </span>│<span class="r5">      </span>│<span class="r5"> preferences?                                                   </span>│<span class="r5"> patient care         </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                              Performance Areas </span>│<span class="r4">             training </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  666 </span>│<span class="r4">                  Filling gaps in trustworthy development of AI </span>│<span class="r4">                trust </span>│<span class="r5"> 2521 </span>│<span class="r5"> In the walled garden: Challenges and opportunities for         </span>│<span class="r5"> ethic course ethical </span>│<span class="r6"> 0.8056 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">      trustworthiness </span>│<span class="r5">      </span>│<span class="r5"> research on the practices of the AI tech industry              </span>│<span class="r5"> introductory         </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">  trustworthy account </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  666 </span>│<span class="r4">                  Filling gaps in trustworthy development of AI </span>│<span class="r4">                trust </span>│<span class="r5"> 1436 </span>│<span class="r5"> Regulating artificial intelligence: Proposal for a global      </span>│<span class="r5"> intelligence wicked  </span>│<span class="r6"> 0.8023 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">      trustworthiness </span>│<span class="r5">      </span>│<span class="r5"> solution                                                       </span>│<span class="r5"> humanity rbi         </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">  trustworthy account </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  978 </span>│<span class="r4">  Detection and Evaluation of bias-inducing Features in Machine </span>│<span class="r4">          explanation </span>│<span class="r5"> 1420 </span>│<span class="r5"> A bio-inspired framework for machine bias interpretation       </span>│<span class="r5"> domain agent         </span>│<span class="r6"> 0.7996 </span>│
│<span class="r3">      </span>│<span class="r4">                                                       learning </span>│<span class="r4">   explainability xai </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> reinforcement        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">          explainable </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> training             </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   60 </span>│<span class="r4">                        Hard choices in artificial intelligence </span>│<span class="r4">     safety assurance </span>│<span class="r5"> 2542 </span>│<span class="r5"> Mapping the individual, social and biospheric impacts of       </span>│<span class="r5"> ethic course ethical </span>│<span class="r6"> 0.7981 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">              risk ml </span>│<span class="r5">      </span>│<span class="r5"> Foundation Models                                              </span>│<span class="r5"> introductory         </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   34 </span>│<span class="r4">      Mechanisms and Constraints Underpinning Ethically Aligned </span>│<span class="r4">         domain agent </span>│<span class="r5"> 1567 </span>│<span class="r5"> Situated accountability: Ethical principles, certification     </span>│<span class="r5"> accountability audit </span>│<span class="r6"> 0.798  </span>│
│<span class="r3">      </span>│<span class="r4">         Artificial Intelligence Systems: An Exploration of key </span>│<span class="r4">        reinforcement </span>│<span class="r5">      </span>│<span class="r5"> standards, and explanation methods in applied AI               </span>│<span class="r5"> auditor auditing     </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                              Performance Areas </span>│<span class="r4">             training </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   34 </span>│<span class="r4">      Mechanisms and Constraints Underpinning Ethically Aligned </span>│<span class="r4">         domain agent </span>│<span class="r5"> 1444 </span>│<span class="r5"> On the distinction between implicit and explicit ethical       </span>│<span class="r5"> moral ethical        </span>│<span class="r6"> 0.7969 </span>│
│<span class="r3">      </span>│<span class="r4">         Artificial Intelligence Systems: An Exploration of key </span>│<span class="r4">        reinforcement </span>│<span class="r5">      </span>│<span class="r5"> agency                                                         </span>│<span class="r5"> obligation morality  </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                              Performance Areas </span>│<span class="r4">             training </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1016 </span>│<span class="r4">                            AITA: AI trustworthiness assessment </span>│<span class="r4">                trust </span>│<span class="r5"> 2238 </span>│<span class="r5"> Effect of confidence and explanation on accuracy and trust     </span>│<span class="r5"> explanation          </span>│<span class="r6"> 0.7962 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">      trustworthiness </span>│<span class="r5">      </span>│<span class="r5"> calibration in AI-assisted decision making                     </span>│<span class="r5"> explainability xai   </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">  trustworthy account </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> explainable          </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  978 </span>│<span class="r4">  Detection and Evaluation of bias-inducing Features in Machine </span>│<span class="r4">          explanation </span>│<span class="r5"> 1402 </span>│<span class="r5"> Explainability&#x27;s gain is optimality&#x27;s loss? How explanations   </span>│<span class="r5"> explanation          </span>│<span class="r6"> 0.792  </span>│
│<span class="r3">      </span>│<span class="r4">                                                       learning </span>│<span class="r4">   explainability xai </span>│<span class="r5">      </span>│<span class="r5"> bias decision-making                                           </span>│<span class="r5"> explainability xai   </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">          explainable </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> explainable          </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  666 </span>│<span class="r4">                  Filling gaps in trustworthy development of AI </span>│<span class="r4">                trust </span>│<span class="r5"> 1567 </span>│<span class="r5"> Situated accountability: Ethical principles, certification     </span>│<span class="r5"> accountability audit </span>│<span class="r6"> 0.7879 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">      trustworthiness </span>│<span class="r5">      </span>│<span class="r5"> standards, and explanation methods in applied AI               </span>│<span class="r5"> auditor auditing     </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">  trustworthy account </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  795 </span>│<span class="r4">                            Decision Support for Safe AI Design </span>│<span class="r4"> instrumental bostrom </span>│<span class="r5"> 2451 </span>│<span class="r5"> Towards a science of human-AI decision making: An overview of  </span>│<span class="r5"> domain agent         </span>│<span class="r6"> 0.7875 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">         thesis agent </span>│<span class="r5">      </span>│<span class="r5"> design space in empirical human-subject studies                </span>│<span class="r5"> reinforcement        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> training             </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   60 </span>│<span class="r4">                        Hard choices in artificial intelligence </span>│<span class="r4">     safety assurance </span>│<span class="r5"> 1870 </span>│<span class="r5"> What to Trust When We Trust Artificial Intelligence (Extended  </span>│<span class="r5"> trust                </span>│<span class="r6"> 0.7834 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">              risk ml </span>│<span class="r5">      </span>│<span class="r5"> Abstract)                                                      </span>│<span class="r5"> trustworthiness      </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> trustworthy account  </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  929 </span>│<span class="r4">         Survey of Scientific Rigor Studied in Machine Learning </span>│<span class="r4">  ml machine cleaning </span>│<span class="r5"> 2272 </span>│<span class="r5"> The values encoded in machine learning research                </span>│<span class="r5"> ml machine cleaning  </span>│<span class="r6"> 0.7823 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">        replicability </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> replicability        </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  978 </span>│<span class="r4">  Detection and Evaluation of bias-inducing Features in Machine </span>│<span class="r4">          explanation </span>│<span class="r5"> 1554 </span>│<span class="r5"> Risk identification questionnaire for detecting unintended     </span>│<span class="r5"> ml machine cleaning  </span>│<span class="r6"> 0.7823 </span>│
│<span class="r3">      </span>│<span class="r4">                                                       learning </span>│<span class="r4">   explainability xai </span>│<span class="r5">      </span>│<span class="r5"> bias in the machine learning development lifecycle             </span>│<span class="r5"> replicability        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">          explainable </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  525 </span>│<span class="r4">       From Plane Crashes to Algorithmic Harm: Applicability of </span>│<span class="r4">     safety assurance </span>│<span class="r5"> 1781 </span>│<span class="r5"> A Conceptual Framework for Ethical Evaluation of Machine       </span>│<span class="r5"> ml machine cleaning  </span>│<span class="r6"> 0.7821 </span>│
│<span class="r3">      </span>│<span class="r4">               Safety Engineering Frameworks for Responsible ML </span>│<span class="r4">              risk ml </span>│<span class="r5">      </span>│<span class="r5"> Learning Systems                                               </span>│<span class="r5"> replicability        </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  952 </span>│<span class="r4"> Adjusting Machine Learning Decisions for Equal Opportunity and </span>│<span class="r4">  fairness fair group </span>│<span class="r5"> 1476 </span>│<span class="r5"> Data-centric factors in algorithmic fairness                   </span>│<span class="r5"> crime police         </span>│<span class="r6"> 0.7748 </span>│
│<span class="r3">      </span>│<span class="r4">                                        Counterfactual Fairness </span>│<span class="r4">       discrimination </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> criminal policing    </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  309 </span>│<span class="r4">                    Designing recommender systems to depolarize </span>│<span class="r4">          recommender </span>│<span class="r5"> 2112 </span>│<span class="r5"> Controlling polarization in personalization: An algorithmic    </span>│<span class="r5"> recommender          </span>│<span class="r6"> 0.7743 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">  recommendation user </span>│<span class="r5">      </span>│<span class="r5"> framework                                                      </span>│<span class="r5"> recommendation user  </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">         polarization </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> polarization         </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3"> 1170 </span>│<span class="r4">   PoisonBench: Assessing Large Language Model Vulnerability to </span>│<span class="r4">    attack backdoored </span>│<span class="r5"> 2644 </span>│<span class="r5"> Analyzing and editing inner mechanisms of backdoored language  </span>│<span class="r5"> attack backdoored    </span>│<span class="r6"> 0.7742 </span>│
│<span class="r3">      </span>│<span class="r4">                                                 Data Poisoning </span>│<span class="r4">  objectionable toxic </span>│<span class="r5">      </span>│<span class="r5"> models                                                         </span>│<span class="r5"> objectionable toxic  </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  922 </span>│<span class="r4">      Application of Artificial Intelligence in Shared Decision </span>│<span class="r4">    healthcare health </span>│<span class="r5"> 2405 </span>│<span class="r5"> Ground(less) truth: A causal framework for proxy labels in     </span>│<span class="r5"> explanation          </span>│<span class="r6"> 0.7728 </span>│
│<span class="r3">      </span>│<span class="r4">                                         Making: Scoping Review </span>│<span class="r4">         patient care </span>│<span class="r5">      </span>│<span class="r5"> human-algorithm decision-making                                </span>│<span class="r5"> explainability xai   </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> explainable          </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  747 </span>│<span class="r4">                                          Inverse Reward Design </span>│<span class="r4">  reward function irl </span>│<span class="r5"> 1708 </span>│<span class="r5"> Reinforcement learning and inverse reinforcement learning with </span>│<span class="r5"> reward function irl  </span>│<span class="r6"> 0.772  </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">              inverse </span>│<span class="r5">      </span>│<span class="r5"> system 1 and system 2                                          </span>│<span class="r5"> inverse              </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  422 </span>│<span class="r4">     Evaluating and Mitigating Discrimination in Language Model </span>│<span class="r4">  fairness fair group </span>│<span class="r5"> 2069 </span>│<span class="r5"> Awareness in practice: tensions in access to sensitive         </span>│<span class="r5"> domain agent         </span>│<span class="r6"> 0.771  </span>│
│<span class="r3">      </span>│<span class="r4">                                                      Decisions </span>│<span class="r4">       discrimination </span>│<span class="r5">      </span>│<span class="r5"> attribute data for antidiscrimination                          </span>│<span class="r5"> reinforcement        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> training             </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   60 </span>│<span class="r4">                        Hard choices in artificial intelligence </span>│<span class="r4">     safety assurance </span>│<span class="r5"> 1682 </span>│<span class="r5"> Defining AI in policy versus practice                          </span>│<span class="r5"> governance compute   </span>│<span class="r6"> 0.7689 </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">              risk ml </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> international        </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> regulatory           </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">   34 </span>│<span class="r4">      Mechanisms and Constraints Underpinning Ethically Aligned </span>│<span class="r4">         domain agent </span>│<span class="r5"> 2330 </span>│<span class="r5"> Tackling algorithmic disability discrimination in the hiring   </span>│<span class="r5"> hiring disability    </span>│<span class="r6"> 0.7667 </span>│
│<span class="r3">      </span>│<span class="r4">         Artificial Intelligence Systems: An Exploration of key </span>│<span class="r4">        reinforcement </span>│<span class="r5">      </span>│<span class="r5"> process: An ethical, legal and technical analysis              </span>│<span class="r5"> resume job           </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                              Performance Areas </span>│<span class="r4">             training </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5">                      </span>│<span class="r6">        </span>│
├──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼──────┼────────────────────────────────────────────────────────────────┼──────────────────────┼────────┤
│<span class="r3">  434 </span>│<span class="r4">            Approval-directed agency and the decision theory of </span>│<span class="r4"> instrumental bostrom </span>│<span class="r5"> 2341 </span>│<span class="r5"> Machine explanations and human understanding                   </span>│<span class="r5"> explanation          </span>│<span class="r6"> 0.7662 </span>│
│<span class="r3">      </span>│<span class="r4">                                          Newcomb-like problems </span>│<span class="r4">         thesis agent </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> explainability xai   </span>│<span class="r6">        </span>│
│<span class="r3">      </span>│<span class="r4">                                                                </span>│<span class="r4">                      </span>│<span class="r5">      </span>│<span class="r5">                                                                </span>│<span class="r5"> explainable          </span>│<span class="r6">        </span>│
└──────┴────────────────────────────────────────────────────────────────┴──────────────────────┴──────┴────────────────────────────────────────────────────────────────┴──────────────────────┴────────┘
</code></pre>
</body>
</html>
